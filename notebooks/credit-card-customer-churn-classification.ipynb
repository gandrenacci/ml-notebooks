{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/gianpieroandrenacci/credit-card-customer-churn-classification?scriptVersionId=154888622\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<h1 style=\"background-color:#002b80;font-family:serif;font-size:350%;color: #fff;text-align:center;border-radius: 50px 50px;\">Credit Card Customer Churn</h1>\n\n\n* [1. Introduction](#1)\n    * [1.1 Import Libraries](#1.1)\n    * [1.2 Custom Functions](#1.2)\n    * [1.3 Load the Data](#1.3)\n    * [1.4 Dataset Description](#1.4)\n* [2. Data Munging](#2)\n    * [2.1 Data Munging](#2.1)\n    * [2.2 Eda (Exploratory Data Analysis)](#2.2)\n* [3. Data Preprocessing](#3)\n    * [3.1 Data Upsampling Using SMOTE](#3.1)\n    * [3.2 Principal Component Analysis Of One Hot Encoded Data](#3.2)  \n* [4. Model Selection And Evaluation](#4) \n    * [4.1 Cross Validation](#4.1)\n    * [4.2 Model Evaluation](#4.2)\n    * [4.3 Model Evaluation On Original Data (Before Upsampling)](#4.3)\n* [5. Results](#5) \n","metadata":{}},{"cell_type":"markdown","source":"![](https://datainnovation.org/wp-content/uploads/2022/03/credit-cards.jpg)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h1 style=\"background-color:#002b80;font-family:Serif;font-size:250%;color: #fff;text-align:center;border-radius: 50px 50px;\">Introduction</h1>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert alert-info\" style=\"font-size:14px; font-family:verdana; line-height: 1.7em; \">\n    ðŸ“Œ &nbsp; Please keep in mind that we are always on our learning journey. I just want to share something that will be interesting for you. If you find this notebook useful in anyway, please upvote it so that it can reach a bigger audience. You can share it with your fellow kagglers. \n</div>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:110%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif\">A manager at the bank is disturbed with more and more customers leaving their credit card services. They would really appreciate if one could predict for them who is gonna get churned so they can proactively go to the customer to provide them better services and turn customers' decisions in the opposite direction</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:110%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif\">The dataset consists of 10,000 customers mentioning their age, salary, marital_status, credit card limit, credit card category, etc. There are nearly 18 features.\nThe dataset name  is Credit Card customers and it is stored on Kaggle.\n</p>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1.1\"></a>\n<h1 style=\"background-color:#002b80;font-family:serif;font-size:250%;color: #fff;text-align:center;border-radius: 50px 50px;\">Libraries and utilities</h1>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom numpy import log\nfrom datetime import date\nimport seaborn as sns # For creating plots\nimport matplotlib.ticker as mtick # For specifying the axes tick format \nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport seaborn as sns\n\n\nfrom numpy import mean\nfrom numpy import std\nfrom pandas import read_csv\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\n    \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import precision_score\n\nfrom imblearn.pipeline import Pipeline as imbpipeline\nfrom imblearn.over_sampling import SMOTE\n\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nsns.set(style = 'white')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \n        ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-01-13T17:02:27.039341Z","iopub.execute_input":"2023-01-13T17:02:27.040292Z","iopub.status.idle":"2023-01-13T17:02:29.720842Z","shell.execute_reply.started":"2023-01-13T17:02:27.040167Z","shell.execute_reply":"2023-01-13T17:02:29.719813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1.2\"></a>\n<h1 style=\"background-color:#002b80;font-family:serif;font-size:250%;color: #fff;text-align:center;border-radius: 50px 50px;\">Custom Functions</h1>","metadata":{}},{"cell_type":"code","source":"def bar_plot(df,ax, column_name= None,xlabel= None, ylabel= None, title= None,colors = ['#042370','#D63F1D'], reorderlist = None):\n    \"\"\"\n    Python function to plot a specific column of dataframe\n    df: dataframe\n    colum_name: column to plot\n    xlabel:  y axis label\n    ylabel:  y axis label\n    colors: colors of the bars\n    \"\"\"\n    #colors\n    colors = colors\n    \n    #percentage of total\n    df = df[column_name].value_counts()*100.0 /len(df)\n     #reorder\n    if reorderlist is not None:\n        df = df.reindex(reorderlist)\n    \n    #group by column and count \n    df.plot(ax= ax,kind='bar',\n             stacked = True,\n             rot = 0,\n             color = colors,\n             #figsize = (15,8)\n           )\n    #format axis and labels\n    #ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n    ax.yaxis.set_visible(False)\n    ax.set_ylabel(ylabel,size = 14)\n    ax.set_xlabel(xlabel,size = 14)\n    ax.set_title(title, size = 14)\n    \n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    \n    # create a list to collect the plt.patches data\n    totals = []\n\n    # find the values and append to list\n    for i in ax.patches:\n        totals.append(i.get_width())\n\n    # set individual bar lables using above list\n    total = sum(totals)\n\n    for i in ax.patches:\n        # get_width pulls left or right; get_y pushes up or down\n        ax.text(i.get_x()+.10, i.get_height()-8.0, str(round((i.get_height()/total), 1))+'%',\\\n                fontsize=16,\n                color='white',\n                weight = 'bold',\n                )\n\n    return \n\n###############################################################\n\n\ndef bar_plot_tot(df, ax, column_name= None,xlabel= None, ylabel= None, title= None,colors = ['#042370','#D63F1D'],reorderlist = None):\n    \"\"\"\n    Python function to plot a specific column of dataframe\n    df: dataframe\n    colum_name: column to plot\n    xlabel:  y axis label\n    ylabel:  y axis label\n    colors: colors of the bars\n    \"\"\"\n    #colors\n    colors = colors\n    #totald\n    df = df[column_name].value_counts()\n     #reorder\n    if reorderlist is not None:\n        df = df.reindex(reorderlist)\n    \n    #group by column and count \n    df.plot.barh(ax= ax,\n                 stacked = True,\n                 rot = 0,\n                 color = colors,\n                # figsize = (15,8)\n                )\n    #format axis and labels\n   # ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n    ax.set_ylabel(ylabel,size = 14)\n    ax.set_xlabel(xlabel,size = 14)\n    ax.set_title(title, size = 14)\n    \n    ax.xaxis.set_visible(False)\n    \n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.spines['left'].set_visible(True)\n    \n    # create a list to collect the plt.patches data\n    totals = []\n\n    # find the values and append to list\n    for i in ax.patches:\n        totals.append(i.get_width())\n    for i, v in enumerate(totals):\n        ax.text(v/2-(v/3), i, str(int(v)), color='white', fontweight='bold', fontsize=16, ha='left', va='center')\n    \n  \n    return \n\n\n########################################\n\ndef bar_stacked_plot(df, ax, label= None, feature= None, title= None,colors = ['#042370','#D63F1D'],reorderlist = None):\n    \"\"\"\n    Python function to plot a stacked bar plot based on feature/label aggregation count\n    df: dataframe\n    label : label of dataframe\n    feature: feature of dataframe\n    title:  plot title\n    colors: colors of the bars\n    reorderlist: specify order if ordinal\n    \"\"\"\n    #bar colors\n    colors = colors\n    \n    #group by label and feature and count the feature\n    df = df.groupby([feature,label]).size().unstack()\n    #reorder\n    if reorderlist is not None:\n        df = df.reindex(reorderlist)\n        \n    # stacked bar plot\n    (df.T*100.0 / df.T.sum()).T.plot(   kind='bar',\n                                                    ax = ax,\n                                                    width = 0.5,\n                                                    stacked = True,\n                                                    rot = 0, \n                                                    #figsize = (18,8),\n                                                    color = colors\n                                                     )\n    #set font\n    csfont = {'fontname':'sans-serif'}\n    #set axis param , title, labels\n    ax.yaxis.set_visible(False)\n    ax.set_ylabel('% ' + feature,size = 14,**csfont)\n    ax.set_xlabel('')\n    ax.legend( loc='center left', bbox_to_anchor =(1,0.5),prop={'size':14},title = label)\n    ax.set_title(title,size = 14,**csfont)\n          \n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n\n    # Code to add the data labels on the stacked bar chart\n    for p in ax.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        ax.annotate('{:.0f}%'.format(height), (p.get_x()+.3*width, p.get_y()+.4*height),\n                    color = 'white',\n                   weight = 'bold',\n                   size = 14)\n\n    return\n\n\n########################################\n\ndef dist_plot_kde(df, ax, label, feature ,xlabel= None,  title= None):\n    \"\"\"\n    Python function to plot the distribution of a feature for positive or negative label values\n    df: dataframe\n    ax: plot definition \n    label: label\n    feature: feature\n    title: title of the plot\n    xlabel:  x axis label\n    \n    \"\"\"\n    #positive label\n    ax = sns.kdeplot(cust_df[feature].loc[(cust_df[label] == 1)],\n                     color=\"Red\", shade = True)\n    #negative label\n    ax = sns.kdeplot(cust_df[feature].loc[(cust_df[label] == 0)],\n                     ax =ax, color=\"Blue\", shade= True, alpha= 0.2)\n    \n    #legend and other plot labels\n    ax.legend([label,\"Not \" + label ],loc='upper right')\n    ax.set_ylabel('Density')\n    ax.set_xlabel(xlabel)\n    ax.set_title(title)\n\n    return \n\n\n########################################\n\n# evaluate a model\ndef evaluate_model(X, y, model):\n    # define evaluation procedure\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    # evaluate model\n    scores = cross_val_score(model, X, y, scoring='recall', cv=cv, n_jobs=-1)\n    return scores\n\n########################################\n\n# define models to test\ndef get_models():\n    models, names = list(), list()\n    # CART\n    models.append(DecisionTreeClassifier())\n    names.append('CART')\n    # SVM\n    models.append(SVC(gamma='scale'))\n    names.append('SVM')\n    # Bagging\n    models.append(BaggingClassifier(n_estimators=100))\n    names.append('BAG')\n    # RF\n    models.append(RandomForestClassifier(n_estimators=100))\n    names.append('RF')\n    # GBM\n    models.append(GradientBoostingClassifier(n_estimators=100))\n    names.append('GBM')\n    #LightGBM\n    models.append(LGBMClassifier())\n    names.append('LightGBM')\n    # LR\n    # models.append(LogisticRegression())\n    # names.append('LR')\n    return models, names","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-01-13T17:02:29.724823Z","iopub.execute_input":"2023-01-13T17:02:29.725561Z","iopub.status.idle":"2023-01-13T17:02:29.769276Z","shell.execute_reply.started":"2023-01-13T17:02:29.725513Z","shell.execute_reply":"2023-01-13T17:02:29.767007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1.3\"></a>\n<h1 style=\"background-color:#002b80;font-family:serif;font-size:250%;color: #fff;text-align:center;border-radius: 50px 50px;\">Load the Data</h1>","metadata":{}},{"cell_type":"code","source":"#load the dataset from csv file\ncust_df = pd.read_csv('/kaggle/input/credit-card-customers/BankChurners.csv')\n\n# PLEASE IGNORE THE LAST 2 COLUMNS (NAIVE BAYES CLASâ€¦). I SUGGEST TO RATHER DELETE IT BEFORE DOING ANYTHING**\ncust_df = cust_df.iloc[:,:-2]\n\n#drop also the customer number\ncust_df.drop(columns =[\"CLIENTNUM\"] , inplace = True)\n\ncust_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:02:29.771063Z","iopub.execute_input":"2023-01-13T17:02:29.772095Z","iopub.status.idle":"2023-01-13T17:02:29.982189Z","shell.execute_reply.started":"2023-01-13T17:02:29.77204Z","shell.execute_reply":"2023-01-13T17:02:29.980972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1.4\"></a>\n<h1 style=\"background-color:#002b80;font-family:serif;font-size:250%;color: #fff;text-align:center;border-radius: 50px 50px;\">Dataset Description</h1>","metadata":{}},{"cell_type":"markdown","source":"* CLIENTNUM > Client number, Unique identifier for the customer holding the account.\n* Attrition_Flag > Internal event (customer activity) variable - if the account is closed then 1 else 0.\n* Customer_Age > Demographic variable - Customerâ€™s Age in Years.\n* Gender > Demographic variable - M=Male, F=Female.\n* Dependent_count > Demographic variable - Number of dependents.  Number of dependents a user has. That is, how many people are dependent on a credit card user for financial support. A higher count tells us that the expenditures can be high.\n* Education_Level > Demographic variable - Educational Qualification of the account holder (example: high school, college graduate, etc.).\n* Marital_Status > Demographic variable - Married, Single, Divorced, Unknown\n* Income_Category > Demographic variable - Annual Income Category of the account holder\n* Card_Category > Product Variable - Type of Card (Blue, Silver, Gold, Platinum).\n* Months_on_book > Period of relationship with bank.\n* Total_Relationship_Count > Total no. of products held by the customer.\n* Months_Inactive_12_mon > No. of months inactive in the last 12 months.\n* Contacts_Count_12_mon > No. of Contacts in the last 12 months.\n* Credit_Limit > Credit Limit on the Credit Card.\n* Total_Revolving_Bal > With revolving credit, a consumer has a line of credit he can keep using and repaying over and over. The balance that carries over from one month to the next is the revolving balance on that loan.\n* Avg_Open_To_Buy > Open to Buy Credit Line (Average of last 12 months). \n* Total_Amt_Chng_Q4_Q1 > Change in Transaction Amount (Q4 over Q1).\n* Total_Trans_Amt > Total Transaction Amount (Last 12 months).\n* Total_Trans_Ct > Total Transaction Count (Last 12 months).\n* Total_Ct_Chng_Q4_Q1 > Change in Transaction Count (Q4 over Q1).\n* Avg_Utilization_Ratio > Average Card Utilization Ratio.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h1 style=\"background-color:#002b80;font-family:Serif;font-size:300%;color: #fff;text-align:center;border-radius: 50px 50px;\">Data Manipulation and Eploration</h1>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2.1\"></a>\n<h1 style=\"background-color:#002b80;font-family:serif;font-size:250%;color: #fff;text-align:center;border-radius: 50px 50px;\">Data Munging</h1>","metadata":{}},{"cell_type":"code","source":"cust_df['Attrition_Flag'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:02:29.985354Z","iopub.execute_input":"2023-01-13T17:02:29.986418Z","iopub.status.idle":"2023-01-13T17:02:29.997298Z","shell.execute_reply.started":"2023-01-13T17:02:29.986363Z","shell.execute_reply":"2023-01-13T17:02:29.996168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:110%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif\">This is our label: Churn or not Churn?</p>","metadata":{}},{"cell_type":"code","source":"# define churn as 1 and 0 (yes or no)\ncust_df[\"Churn\"] = np.where(cust_df[\"Attrition_Flag\"] == \"Attrited Customer\", 1, 0)\n\n#remove Attrition_Flag\ncust_df.drop(columns=[\"Attrition_Flag\"],inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:02:29.999123Z","iopub.execute_input":"2023-01-13T17:02:29.999525Z","iopub.status.idle":"2023-01-13T17:02:30.013713Z","shell.execute_reply.started":"2023-01-13T17:02:29.999461Z","shell.execute_reply":"2023-01-13T17:02:30.011758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check null values\ncust_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:02:30.015631Z","iopub.execute_input":"2023-01-13T17:02:30.016501Z","iopub.status.idle":"2023-01-13T17:02:30.032676Z","shell.execute_reply.started":"2023-01-13T17:02:30.016462Z","shell.execute_reply":"2023-01-13T17:02:30.030629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:110%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif\">We are lucky! There are no nulls</p>","metadata":{}},{"cell_type":"code","source":"# let's check Income Category\ncust_df['Income_Category'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:02:30.034335Z","iopub.execute_input":"2023-01-13T17:02:30.034716Z","iopub.status.idle":"2023-01-13T17:02:30.043427Z","shell.execute_reply.started":"2023-01-13T17:02:30.034683Z","shell.execute_reply":"2023-01-13T17:02:30.04247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace the unknown incomes with the mode of the Income_Category\ncust_df['Income_Category'].replace('Unknown', cust_df['Income_Category'].mode()[0], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:02:30.04515Z","iopub.execute_input":"2023-01-13T17:02:30.045761Z","iopub.status.idle":"2023-01-13T17:02:30.063364Z","shell.execute_reply.started":"2023-01-13T17:02:30.045724Z","shell.execute_reply":"2023-01-13T17:02:30.061875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2.2\"></a>\n<h1 style=\"background-color:#002b80;font-family:serif;font-size:250%;color: #fff;text-align:center;border-radius: 50px 50px;\">EDA (Exploratory Data Analysis)</h1>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:150%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\"> % Customer Churn</p>","metadata":{}},{"cell_type":"code","source":"from matplotlib import gridspec\n# set figure and size\nfig = plt.figure()\nfig.set_figheight(6)\nfig.set_figwidth(15)\n\n# geometry(Grid we created for subplots),\nspec = gridspec.GridSpec(ncols=2, nrows=1,\n                         wspace=0.5,\n                         hspace=0.5)\n\n# ax1 will take first column\nax1 = fig.add_subplot(spec[0])\nbar_plot(cust_df,ax1,column_name= \"Churn\",xlabel= \"Churn\", ylabel= \"% Churn Rate\", title= \"% Credit Card Customer Churn\")\n\n# ax2 will take second column\nax2 = fig.add_subplot(spec[1])\nbar_plot_tot(cust_df,ax2,column_name= \"Churn\",xlabel= \"Churn\", ylabel= \"# Churn\", title= \"# Credit Card Customer Churn\",colors = 'b')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-01-13T17:02:30.064972Z","iopub.execute_input":"2023-01-13T17:02:30.066354Z","iopub.status.idle":"2023-01-13T17:02:30.367476Z","shell.execute_reply.started":"2023-01-13T17:02:30.0663Z","shell.execute_reply":"2023-01-13T17:02:30.366072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:130%; font-weight: bold; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif\">We have  16.1% of customers who have churned. Thus, it's a bit difficult to train our model to predict churning customers. It is an imbalanced data set.\n</p>  ","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:110%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif\"> \n</p>  ","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:150%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\"> Income Category</p>","metadata":{}},{"cell_type":"code","source":"from matplotlib import gridspec\n# set figure and size\nfig = plt.figure()\nfig.set_figheight(8)\nfig.set_figwidth(22)\n\n# geometry(Grid we created for subplots),\nspec = gridspec.GridSpec(ncols=2, nrows=1,\n                         wspace=0.5,\n                         hspace=0.5)\n\n#reorder category \nreorderlist = ['Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +']\n\n# ax1 will take first column\nax1 = fig.add_subplot(spec[0])\nbar_stacked_plot(cust_df,ax1 ,label= 'Churn', feature= 'Income_Category', title= 'Churn by Income Category', reorderlist = reorderlist)\n\n# ax2 will take second column\nax2 = fig.add_subplot(spec[1])\nbar_plot_tot(cust_df,ax2,column_name= 'Income_Category',xlabel= \"Income Category\", ylabel= \"# Income Category\", title= \"# Income Category\",colors=  ['b'] ,reorderlist = reorderlist)","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-01-13T17:02:30.369568Z","iopub.execute_input":"2023-01-13T17:02:30.370052Z","iopub.status.idle":"2023-01-13T17:02:30.974047Z","shell.execute_reply.started":"2023-01-13T17:02:30.370007Z","shell.execute_reply":"2023-01-13T17:02:30.972811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:120%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif\">Very low income and very high income tend to churn a little bit more</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:150%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\"> Education Level</p>","metadata":{}},{"cell_type":"code","source":"from matplotlib import gridspec\n# set figure and size\nfig = plt.figure()\nfig.set_figheight(8)\nfig.set_figwidth(25)\n\n# geometry(Grid we created for subplots),\nspec = gridspec.GridSpec(ncols=2, nrows=1,\n                         wspace=0.5,\n                         hspace=0.5)\n\n#reorder the categories\nreorderlist =['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate']\n\n# ax1 will take first column\nax1 = fig.add_subplot(spec[0])\nbar_stacked_plot(cust_df,ax1 ,label= 'Churn', feature= 'Education_Level', title= 'Churn by Education_Level', reorderlist = reorderlist)\n\n# ax2 will take second column\nax2 = fig.add_subplot(spec[1])\nbar_plot_tot(cust_df,ax2,column_name= 'Education_Level',  title= \"# Education_Level distribution\",colors=  ['b'] )","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-01-13T17:02:30.97938Z","iopub.execute_input":"2023-01-13T17:02:30.979783Z","iopub.status.idle":"2023-01-13T17:02:31.433769Z","shell.execute_reply.started":"2023-01-13T17:02:30.979748Z","shell.execute_reply":"2023-01-13T17:02:31.432513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:120%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif\">Post-graduate and Doctorate tend to churn a little bit more</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:150%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\"> Gender</p>","metadata":{}},{"cell_type":"code","source":"from matplotlib import gridspec\n# set figure and size\nfig = plt.figure()\nfig.set_figheight(6)\nfig.set_figwidth(15)\n\n# geometry(Grid we created for subplots),\nspec = gridspec.GridSpec(ncols=2, nrows=1,\n                         wspace=0.5,\n                         hspace=0.5)\n\n# ax1 will take first column\nax1 = fig.add_subplot(spec[0])\nbar_stacked_plot(cust_df,ax1 ,label= 'Churn', feature= 'Gender', title= 'Churn by Gender')\n\n# ax2 will take second column\nax2 = fig.add_subplot(spec[1])\nbar_plot_tot(cust_df,ax2,column_name= 'Gender',  title= \"# Gender distribution\",colors=  ['b'] )","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-01-13T17:02:31.435218Z","iopub.execute_input":"2023-01-13T17:02:31.436112Z","iopub.status.idle":"2023-01-13T17:02:31.851584Z","shell.execute_reply.started":"2023-01-13T17:02:31.43606Z","shell.execute_reply":"2023-01-13T17:02:31.850516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:150%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\"> Card Category</p>","metadata":{}},{"cell_type":"code","source":"# set figure and size\nfig = plt.figure()\nfig.set_figheight(8)\nfig.set_figwidth(25)\n\n# geometry(Grid we created for subplots),\nspec = gridspec.GridSpec(ncols=2, nrows=1,\n                         wspace=0.5,\n                         hspace=0.5)\n\n#reorder the categories\nreorderlist =['Blue', 'Silver', 'Gold', 'Platinum']\n\n# ax1 will take first column\nax1 = fig.add_subplot(spec[0])\nbar_stacked_plot(cust_df,ax1 ,label= 'Churn', feature= 'Card_Category', title= 'Churn by Card Category', reorderlist = reorderlist)\n\n# ax2 will take second column\nax2 = fig.add_subplot(spec[1])\nbar_plot_tot(cust_df,ax2,column_name= 'Card_Category',  title= \"# Card Category distribution\",colors=  ['b'] )","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-01-13T17:02:31.852678Z","iopub.execute_input":"2023-01-13T17:02:31.853371Z","iopub.status.idle":"2023-01-13T17:02:32.222206Z","shell.execute_reply.started":"2023-01-13T17:02:31.853338Z","shell.execute_reply":"2023-01-13T17:02:32.221061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:150%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\"> Customer Age</p>","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(9,7))\ndist_plot_kde(df = cust_df,ax = ax,label = 'Churn', feature = \"Customer_Age\" ,xlabel= 'Customer Age',  title= 'Customer Age Churn vs Not Churn Distribution')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-01-13T17:02:32.223774Z","iopub.execute_input":"2023-01-13T17:02:32.224524Z","iopub.status.idle":"2023-01-13T17:02:32.52839Z","shell.execute_reply.started":"2023-01-13T17:02:32.224475Z","shell.execute_reply":"2023-01-13T17:02:32.527454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:120%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif\">Age has no effect on Churn</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:150%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\"> Credit Limit</p>","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(9,7))\ndist_plot_kde(df = cust_df,ax = ax,label = 'Churn', feature = \"Credit_Limit\" ,xlabel= 'Credit Limit',  title= 'Credit Limit Churn vs Not Churn Distribution')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-01-13T17:02:32.529502Z","iopub.execute_input":"2023-01-13T17:02:32.530176Z","iopub.status.idle":"2023-01-13T17:02:32.894857Z","shell.execute_reply.started":"2023-01-13T17:02:32.530138Z","shell.execute_reply":"2023-01-13T17:02:32.893743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:120%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif\">Credit limit has little effect on Churn. There are more customers with low credit limit that do not churn </p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:150%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\"> Total Transactions Amount</p>","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(9,7))\ndist_plot_kde(df = cust_df,ax = ax,label = 'Churn', feature = \"Total_Trans_Amt\" ,xlabel= 'Total_Trans_Amt',  title= 'Total Trans Amount Churn vs Not Churn Distribution')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-01-13T17:02:32.89624Z","iopub.execute_input":"2023-01-13T17:02:32.896622Z","iopub.status.idle":"2023-01-13T17:02:33.278153Z","shell.execute_reply.started":"2023-01-13T17:02:32.896556Z","shell.execute_reply":"2023-01-13T17:02:33.276827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:120%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif\">Total transaction amount has a relevant effect on Churn. Customers with low Total Transactions Amount tend to churn more</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:150%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\"> CORRELATION MATRIX</p>","metadata":{}},{"cell_type":"code","source":"#slect numerical feature and exlude the label\nnum_data = cust_df.select_dtypes(exclude=['object'])\ndf_corr_matrix = num_data.iloc[:,:-1].corr()\n\n#if correlation is low put 0 (for correlation matrix redability)\ndf_corr_matrix[abs(df_corr_matrix) < 0.1] = 0 \n\n#plot the correlation matrix\nplt.figure(figsize=(30, 12))\n\n# define the mask to set the values in the upper triangle to True\nmask = np.triu(np.ones_like(df_corr_matrix.corr(), dtype=np.bool_))\nheatmap = sns.heatmap(df_corr_matrix.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')\nheatmap.set_title('Customer Dataset Correlation Heatmap', fontdict={'fontsize':22}, pad=16);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-01-13T17:02:33.279971Z","iopub.execute_input":"2023-01-13T17:02:33.280708Z","iopub.status.idle":"2023-01-13T17:02:34.482669Z","shell.execute_reply.started":"2023-01-13T17:02:33.280662Z","shell.execute_reply":"2023-01-13T17:02:34.481491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:110%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\"> Considerations</p>","metadata":{}},{"cell_type":"markdown","source":"* Customer age and Months on book have a high correlation because younger customers just got the possibility of getting a credit card thing\n* Avg_Open_To_Buy and Credit_Limit have a high correlation because they are telling the same thing\n* Total Transaction Amount is high correlated with Total Transacion Count because usually the amount tends to get higher as the count of transactions grow","metadata":{}},{"cell_type":"markdown","source":"The features 'Credit_Limit', 'Total_Revolving_Bal','Avg_Open_To_Buy','Total_Ct_Chng_Q4_Q1','Months_on_book', 'Total_Trans_Ct'\n\n**could be eliminated** beacuse of high correlation with other features feature.\n\nI've tried to eliminate them, but the models performance are not as good as with all the features. **The kind of models that we are going to use are not affected by multicollinearity**.\nInfact highly correlated variables won't cause multi-collinearity issues in random forest models.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n<h1 style=\"background-color:#002b80;font-family:Serif;font-size:300%;color: #fff;text-align:center;border-radius: 50px 50px;\">Model selection and evaluation</h1>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4.1\"></a>\n<h1 style=\"background-color:#002b80;font-family:serif;font-size:250%;color: #fff;text-align:center;border-radius: 50px 50px;\">Test different models performance</h1>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:110%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\"> Encode and Split</p>","metadata":{}},{"cell_type":"code","source":"# divide features and label , encode label\ny = cust_df['Churn'].values\nX = cust_df.drop(columns = ['Churn'])\n#y = LabelEncoder().fit_transform(y)\n\n#categorical and numerical \ncat_ix = X.select_dtypes(include=['object', 'bool']).columns\nnum_ix = X.select_dtypes(include=['int64', 'float64']).columns\n\n\n# define models\nmodels, names = get_models()\nresults = list()\n\n#define pipeline for categorical transformer \ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))])\n\n#split train and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:02:34.48375Z","iopub.execute_input":"2023-01-13T17:02:34.484187Z","iopub.status.idle":"2023-01-13T17:02:34.507029Z","shell.execute_reply.started":"2023-01-13T17:02:34.48415Z","shell.execute_reply":"2023-01-13T17:02:34.505752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:110%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\"> Build the Pipeline</p>","metadata":{}},{"cell_type":"markdown","source":"How to deal with imbalance data. Perform over-sampling using SMOTE.\n\nThis object is an implementation of SMOTE - Synthetic Minority Over-sampling Technique as presented in ","metadata":{}},{"cell_type":"code","source":"# evaluate each models\n\n#smote for oversampling\nsmt = SMOTE(random_state=42)\n\nfor i in range(len(models)):\n    # define steps\n    steps = [('c',categorical_transformer,cat_ix), ('n',MinMaxScaler(),num_ix)]\n    # one hot encode categorical, normalize numerical\n    ct = ColumnTransformer(steps)\n    # wrap the model i a pipeline\n    pipeline = imbpipeline(steps=[('t',ct),('smt', smt),('m',models[i])])\n    # evaluate the model and store results\n    scores = evaluate_model(X_train, y_train, pipeline)\n    results.append(scores)\n    # summarize performance\n    print('>%s %.3f (%.3f)' % (names[i], mean(scores), std(scores)))\n    \n# plot the results\nplt.figure(figsize=(15, 10))\nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:02:34.508632Z","iopub.execute_input":"2023-01-13T17:02:34.509064Z","iopub.status.idle":"2023-01-13T17:07:52.785643Z","shell.execute_reply.started":"2023-01-13T17:02:34.509029Z","shell.execute_reply":"2023-01-13T17:07:52.784114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:110%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\">The best model is LightGBM</p>","metadata":{}},{"cell_type":"markdown","source":"**LightGBM** is a gradient boosting framework (**implemented by Microsoft**) that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n\n* Faster training speed and higher efficiency.\n* Lower memory usage.\n* Better accuracy.\n* Support of parallel, distributed, and GPU learning.\n* Capable of handling large-scale data.\n\n[Lightgbm](https://lightgbm.readthedocs.io/en/v3.3.2/)","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:110%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\">Search for the best parameters</p>","metadata":{}},{"cell_type":"code","source":"# build the parameters grid \n\nparam_grid = \\\n[\n    {  \n    \"m__learning_rate\":[0.1, 0.5],\n    \"m__max_depth\":[30],\n    \"m__num_leaves\":[10,100],\n    \"m__feature_fraction\":[0.1,1.0],\n    \"m__subsample\":[0.1,1.0],\n    }\n]\nparam_grid","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:07:52.787948Z","iopub.execute_input":"2023-01-13T17:07:52.788472Z","iopub.status.idle":"2023-01-13T17:07:52.79989Z","shell.execute_reply.started":"2023-01-13T17:07:52.78842Z","shell.execute_reply":"2023-01-13T17:07:52.798654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the location of the dataset\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nsmt = SMOTE(random_state=42)\n\n#BGC = BaggingClassifier()\nCLS = LGBMClassifier()\n\n# define steps\nsteps = [('c',categorical_transformer,cat_ix), ('n',MinMaxScaler(),num_ix)]\n# one hot encode categorical, normalize numerical\nct = ColumnTransformer(steps)\n# wrap the model i a pipeline\npipeline = imbpipeline(steps=[('t',ct),('smt',smt),('m',CLS)])\n# evaluate the model and store results\ngrid_search = GridSearchCV(pipeline, param_grid, cv=5,\n                       scoring='recall',\n                       return_train_score=True,n_jobs = -1, refit=True)\n\ngrid_search.fit(X_train, y_train)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-01-13T17:07:52.801885Z","iopub.execute_input":"2023-01-13T17:07:52.802276Z","iopub.status.idle":"2023-01-13T17:08:12.92978Z","shell.execute_reply.started":"2023-01-13T17:07:52.802223Z","shell.execute_reply":"2023-01-13T17:08:12.928519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ncvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:08:12.931153Z","iopub.execute_input":"2023-01-13T17:08:12.931487Z","iopub.status.idle":"2023-01-13T17:08:12.93821Z","shell.execute_reply.started":"2023-01-13T17:08:12.931457Z","shell.execute_reply":"2023-01-13T17:08:12.936937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:130%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\">The best parameters are:</p>","metadata":{}},{"cell_type":"code","source":"print(grid_search.best_score_)\ngrid_search.best_params_\n","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:08:12.940028Z","iopub.execute_input":"2023-01-13T17:08:12.940471Z","iopub.status.idle":"2023-01-13T17:08:12.953218Z","shell.execute_reply.started":"2023-01-13T17:08:12.940429Z","shell.execute_reply":"2023-01-13T17:08:12.952049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:130%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\">Test final model</p> ","metadata":{}},{"cell_type":"code","source":"name = \"LGBMClassifier\"\nsmt = SMOTE(random_state=42)\n\n\nCLS = LGBMClassifier(feature_fraction = 1.0,learning_rate=0.5,\n                         max_depth= 30,num_leaves= 10,subsample= 0.1)\n\n# define steps\nsteps = [('c',categorical_transformer,cat_ix), ('n',MinMaxScaler(),num_ix)]\n# one hot encode categorical, normalize numerical\nct = ColumnTransformer(steps)\n# wrap the model i a pipeline\npipeline = imbpipeline(steps=[('t',ct),('smt',smt),('m',CLS)])\n# evaluate the model and store results\npipeline.fit(X_train, y_train)\n#predict\npreds = pipeline.predict(X_test)\npreds","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-01-13T17:08:12.95456Z","iopub.execute_input":"2023-01-13T17:08:12.955418Z","iopub.status.idle":"2023-01-13T17:08:13.308255Z","shell.execute_reply.started":"2023-01-13T17:08:12.955376Z","shell.execute_reply":"2023-01-13T17:08:13.307284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:130%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\">Evaluate the model</p> ","metadata":{}},{"cell_type":"code","source":"#evaluate final model\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nimport lightgbm as ltb\n# Print the prediction accuracy\npred_accuracy = metrics.accuracy_score(y_test, preds)\npred_recall = metrics.recall_score (y_test, preds)\npred_precision = metrics.precision_score (y_test, preds)\n\nprint('Accuracy: ' f\"{pred_accuracy:,.4%}\")\nprint('Recall: ' f\"{pred_recall:,.4%}\")\nprint('Precision: ' f\"{pred_precision:,.4%}\")\n\nconfusion_matrix(y_test,preds)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:08:13.312672Z","iopub.execute_input":"2023-01-13T17:08:13.315558Z","iopub.status.idle":"2023-01-13T17:08:13.33136Z","shell.execute_reply.started":"2023-01-13T17:08:13.315509Z","shell.execute_reply":"2023-01-13T17:08:13.33038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:130%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\">Confusion Matrix</p> ","metadata":{}},{"cell_type":"code","source":"cfm = confusion_matrix(y_test, preds)\nplt.figure(figsize=(8,8))\nsns.heatmap(cfm, annot=True)\n\nplt.xlabel('Predicted classes')\nplt.ylabel('Actual classes')","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:08:13.332564Z","iopub.execute_input":"2023-01-13T17:08:13.333452Z","iopub.status.idle":"2023-01-13T17:08:13.575696Z","shell.execute_reply.started":"2023-01-13T17:08:13.333418Z","shell.execute_reply":"2023-01-13T17:08:13.574714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:130%; background-color:#F8F9F9;border-radius: 0px 30px;text-align:center;font-family:Sans-serif;font-weight:bold\">Features importance</p> ","metadata":{}},{"cell_type":"code","source":"\nfeature_imp = pd.DataFrame(sorted(zip(CLS.feature_importances_,X.columns)), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-01-13T17:08:13.577342Z","iopub.execute_input":"2023-01-13T17:08:13.57817Z","iopub.status.idle":"2023-01-13T17:08:13.974629Z","shell.execute_reply.started":"2023-01-13T17:08:13.578132Z","shell.execute_reply":"2023-01-13T17:08:13.972896Z"},"trusted":true},"execution_count":null,"outputs":[]}]}